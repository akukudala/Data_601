{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "601_Assignment07.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMXshAqbC2xC7jAd/rbu5hT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akukudala/Data_601/blob/main/Assignment07/601_Assignment07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aq3FINB2ti8E",
        "outputId": "77260ca4-5fb0-45b2-9003-7c5081253b7b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "HuVFgjtXkVuY"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import io\n",
        "import codecs\n",
        "#>>>f = io.open(\"test\", mode=\"r\", encoding=\"utf-8\")\n",
        "def remove_punc(test):\n",
        "    #test = open(test, \"r\")\n",
        "    #text = open(test, mode=\"r\", encoding='utf-8').read()\n",
        "    #text = test.encode('UTF-8')\n",
        "    #test = test.read()\n",
        "    \n",
        "    text = codecs.open(test, 'r', encoding='utf-8',\n",
        "                 errors='ignore').read()\n",
        "    #text.close()\n",
        "\n",
        "    for e in string.punctuation:\n",
        "        if e in text:\n",
        "            text = text.replace(e, \"\")\n",
        "            text_list = text.split()\n",
        "            words = {}\n",
        "    for word in text_list:\n",
        "        if word in words:\n",
        "            words[word] +=1\n",
        "        else:\n",
        "            words[word] = 1\n",
        "\n",
        "    list1 = []\n",
        "    for key, val in words.items():\n",
        "        if val == 1:\n",
        "            list1.append(key)\n",
        "    print (','.join(list1))\n",
        "    str2 = \" \".join(str(x) for x in list1)\n",
        "    return str2\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def stpwrd(Full_list):\n",
        "    from nltk.corpus import stopwords\n",
        "\n",
        "    from nltk.tokenize import word_tokenize\n",
        "    from nltk.corpus import stopwords\n",
        "    import nltk\n",
        "    nltk.download('punkt')\n",
        "    nltk.download('stopwords')\n",
        "    text_tokens = word_tokenize(Full_list)\n",
        "\n",
        "    tokens_without_sw = [word for word in text_tokens if not word in stopwords.words()]\n",
        "\n",
        "    return tokens_without_sw"
      ],
      "metadata": {
        "id": "19lyOQ_4sbuO"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finalliststr1 = stpwrd(remove_punc(\"week_8_document2.txt\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgrgVqdstJa8",
        "outputId": "111f883f-3462-41d1-c732-e41ce14c9d74"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dr,Earl,Vickers,Boring,Bedtime,Stories,Anthology,Insomniacs,started,harmlessly,enough,highschool,science,fair,project,Why,Are,Yawns,Contagious,thing,led,here,worlds,foremost,expert,cared,topic,equally,suicidal,career,conferences,cocktail,For,reasons,fully,understand,discussion,considered,rude,andor,act,itself,mere,mention,inevitably,bring,minor,epidemic,uncontrollable,whether,back,disguised,right,face,way,ruined,countless,conventions,meetings,concerts,bachelor,wedding,receptions,number,invitations,both,professional,dwindled,nothing,doubly,unfortunate,because,lasted,encounters,served,laboratories,additional,field,conclusion,illfated,encounter,quietly,retire,corner,room,take,meticulous,notes,Sometimes,surreptitiously,stopwatch,carefully,noting,length,initial,gestation,predelay,duration,inspiratory,phase,precise,moment,acme,orgasmic,peak,short,expiration,interval,bystanders,afflicted,gather,much,data,possible,regarding,involved,effort,derive,correlations,personality,type,susceptibility,Realizing,most,share,fascination,learning,yawnings,paralinguistic,value,complex,arousal,defense,reflex,origin,reticular,brainstem,theories,relation,borderline,hypoxia,tried,spice,famous,quotations,Aristotles,As,urinates,sees,hears,doing,someone,even,used,joke,pharmacological,connection,spontaneous,erection,Am,I,death,are,just,happy,see,me,without,fail,recipient,conversations,ask,excused,covering,mouth,make,beeline,anywhere,Sadly,work,years,seemed,unable,concentrate,Often,fall,asleep,middle,writing,Even,complete,article,either,accepted,rejected,simply,ignored,manuscript,become,unreadable,academic,world,publish,path,Students,came,office,more,missed,bright,inquisitive,lighting,briefly,eventually,disappearing,heavy,lids,flame,curiosity,gradually,flickering,wind,physiologic,finally,extinguished,serotoninergic,inhibition,neuromuscular,spindles,adrenocorticotropic,hormonerelated,peptides,hypothalamic,dopaminergic,mechanisms,particularly,enjoyed,showing,nearly,fascinating,hung,wall,believed,should,have,been,priceless,apparently,dated,Renaissance,obtain,ignorant,owner,few,hundred,dollars,suspected,spoken,Leonardo,da,Vinci,artist,painted,made,everybody,saw,repeatedly,kept,represented,hoped,impress,reality,immediacy,phenomenon,trigger,avalanche,questions,often,suddenly,remember,urgent,appointment,side,campus,His,lectures,reputation,mesmerizing,least,somniferous,rumored,render,entire,classroom,unconscious,certainly,exaggeration,displayed,remarkable,ingenuity,devising,ways,conceal,stifle,swallow,They,developed,elaborate,alarm,systems,keep,exams,called,class,Meanwhile,insomnia,frequently,audit,classes,search,cure,condition,On,evening,sat,reviewing,recalled,some,satisfaction,breakthroughs,areas,fetal,temporary,yawnrelated,hearing,loss,hysterical,paroxysmal,fondly,remembered,mostly,seated,ovation,received,those,still,finished,presenting,groundbreaking,mate,selection,While,nontechnical,book,Joy,Yawning,monograph,Proudly,never,quite,reached,broader,audiences,whom,intended,nonetheless,proud,efforts,popularize,done,all,could,Not,bad,reflected,stretching,out,closing,Soon,perhaps,dean,mayor,President,awaken,him,asking,help,something,kidnapping,terrorist,plot,expertise,desperately,needed,megaphone,cell,phone,placed,dulcet,tones,calming,relaxing,defusing,situation,everyone,drifts,off,soft,warm,comfortable,problems,cant,wait,day,now,wake,tomorrow,thanks,grateful,nation,httpswwwmuseumofconceptualartcomstoriesboringbedtimestoriesdryawnhtml\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install python-docx "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRRJiZ8byqTR",
        "outputId": "4130745b-3a7c-4875-d359-faccfe78ab17"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from python-docx) (4.2.6)\n",
            "Building wheels for collected packages: python-docx\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184507 sha256=4916c00b62e57ba87baed7cba774c9b93d13834092aa909115a8f6890a2010a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/6f/b9/d798122a8b55b74ad30b5f52b01482169b445fbb84a11797a6\n",
            "Successfully built python-docx\n",
            "Installing collected packages: python-docx\n",
            "Successfully installed python-docx-0.8.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install docx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9KVNGXJyYV7",
        "outputId": "63039912-34a2-413a-e2fc-d117a44fe03c"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: docx in /usr/local/lib/python3.7/dist-packages (0.2.4)\n",
            "Requirement already satisfied: Pillow>=2.0 in /usr/local/lib/python3.7/dist-packages (from docx) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from docx) (4.2.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import docx\n",
        "from docx import Document\n",
        "\n",
        "document = Document('week_8_document1.docx')\n",
        "for para in document.paragraphs:\n",
        "    docfilrtxt= para.text\n",
        "\n",
        "f = open(\"week_8_document1.txt\", \"a\")\n",
        "f.write(docfilrtxt)\n",
        "f.close()"
      ],
      "metadata": {
        "id": "5IhFArnSyRNY"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finalliststr2 = stpwrd(remove_punc(\"week_8_document1.txt\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKwB1mmptWLj",
        "outputId": "248457f6-68e1-4e15-ea55-9accd5d7637e"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "main,base,corpus,The,analysis,processing,various,types,also,subject,much,work,computational,recognition,machine,translation,where,they,often,used,create,hidden,Markov,models,part,tagging,other,purposes,frequency,lists,derived,from,them,useful,teaching,can,be,considered,a,type,foreign,aid,contextualised,grammatical,acquired,by,nonnative,users,through,exposure,authentic,texts,allows,learners,grasp,manner,sentence,formation,target,enabling,effective\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('file_{0}.dat','w') as f:\n",
        "       f.write(\" \".join(str(x) for x in finalliststr1))\n",
        "       f.write(\" \".join(str(x) for x in finalliststr2))"
      ],
      "metadata": {
        "id": "0own6TA2xItn"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(2):\n",
        "   with open('file_{0}.dat'.format(i),'w') as f:\n",
        "       f.write(\" \".join(str(x) for x in finalliststr1))\n",
        "       f.write(\" \".join(str(x) for x in finalliststr2))"
      ],
      "metadata": {
        "id": "ZUFnlRRRpXN7"
      },
      "execution_count": 103,
      "outputs": []
    }
  ]
}